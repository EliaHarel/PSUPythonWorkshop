{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python will use a single processor by default.  We can do things with mulptiple cores in many ways.  Here are some common methods for doing so with examples using the multiprocessing module using the process and pool examples.\n",
    "\n",
    "The overhead associated with parallelization is discussed.  Note that in the discussion here, no distinction is made between concurrency and parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiprocessing module has a process function that allows us to spawn individual threads, which may do similar or different things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 squared to 1 by pid: 92505\n",
      "2 squared to 4 by pid: 92506\n",
      "3 squared to 9 by pid: 92507\n",
      "4 squared to 16 by pid: 92508\n",
      "5 squared to 25 by pid: 92509\n"
     ]
    }
   ],
   "source": [
    "import os as os\n",
    "from multiprocessing import Process\n",
    "\n",
    "def squareInput( inputVal ):\n",
    "    output = inputVal ** 2\n",
    "    pid = os.getpid()\n",
    "    print( '{0} squared to {1} by pid: {2}'.format(inputVal, output, pid) )\n",
    "     \n",
    "vals = [1, 2, 3, 4, 5]\n",
    "procsUsed = []\n",
    "\n",
    "for indVal, valHere in enumerate(vals):\n",
    "    procThis = Process( target = squareInput, args = ( valHere, ) )\n",
    "    procsUsed.append( procThis )\n",
    "    procThis.start( )\n",
    "\n",
    "for procThis in procsUsed:\n",
    "    procThis.join( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiprocessing module allows you to map inputs to a repeated function onto a pool of processors using the pool function.\n",
    "\n",
    "Be sure to close the pool of processers - you may get 'Open File' errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def fxnSer( input ):\n",
    "    return input * input\n",
    "\n",
    "procs = Pool( 2 )\n",
    "outs = procs.map( fxnSer, range( 10 ) )\n",
    "print( outs )\n",
    "procs.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.6 ms ± 2.84 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "procs = Pool( 1 )\n",
    "outs = procs.map(fxnSer, range(1000))\n",
    "procs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.9 ms ± 460 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "procs = Pool( 2 )\n",
    "outs = procs.map( fxnSer, range( 1000 ) )\n",
    "procs.close( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is overhead associated with creating the parallel processes - what's done in the function needs to be compute intensive enough to take enough time.\n",
    "\n",
    "Addditionally, not all compute resources will provide multiple CPUs - know the limitations of the jupyter environment you are trying to run in.  (Also, just because we have access to it, doesn't mean we can use it with other tasks and users on the system going.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"#-# How many cpus do I have access to?\")\n",
    "print( mp.cpu_count( ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do I/O in parallel using multiprocessing by breaking up a file into sections to read with individual processors.  Here, we read in the complete works of Shakespeare (available: https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def readLine( line ):\n",
    "    return \"%s\" % line\n",
    "\n",
    "procs = 4\n",
    "pool = Pool( procs )\n",
    "with open( 't8.shakespeare.txt' ) as skspFile:\n",
    "    fullText = pool.map( readLine, skspFile, procs)\n",
    "\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.99 s ± 681 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "procs = 1\n",
    "pool = Pool( procs )\n",
    "with open( 't8.shakespeare.txt' ) as skspFile:\n",
    "    fullText = pool.map( readLine, skspFile, procs)\n",
    "\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.32 s ± 222 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "procs = 2\n",
    "pool = Pool( procs )\n",
    "with open( 't8.shakespeare.txt' ) as skspFile:\n",
    "    fullText = pool.map( readLine, skspFile, procs)\n",
    "\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.82 s ± 21.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "procs = 4\n",
    "pool = Pool( procs )\n",
    "with open( 't8.shakespeare.txt' ) as skspFile:\n",
    "    fullText = pool.map( readLine, skspFile, procs)\n",
    "\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll note that the time likely isn't being cut down by half each time - the overhead associated with the parallelization (creating the tasks, fitting the data back together) won't allow this to be a perfect half.  It is possible to have times that are lower than half when the compute resources are shared with other tasks/users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Parallelization Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are may different parallelization modules for python.  Here are some of the most commonly used:\n",
    "* mpi4py: Use MPI commands within python; must link to existing MPI library\n",
    "* PyMP: OpenMP for python\n",
    "* VecPy: SIMD extensions for vectorization (Python 3 only)\n",
    "\n",
    "Find more information at: https://wiki.python.org/moin/ParallelProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables used in this example\n",
    "import numpy as np\n",
    "largeArray = np.arange(50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that cubes each number given to it.  Use pool to run this on largeArray using 1, 2, ..., topNum where topNum is the number of cores you have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
