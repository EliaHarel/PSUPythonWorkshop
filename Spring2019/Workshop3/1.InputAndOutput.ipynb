{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeding Up I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I/O is one of the most time-intensive things we do in any coding language.  If you find yourself reading in large data sets or reading in the same data sets over and over, it might be worthwhile to see if there is a better method for your input, such as saving your data once in a faster-to-read method.\n",
    "\n",
    "This notebook looks at some different I/O methods:\n",
    "* Numpy's binary forms (compressed and non-compressed)\n",
    "* Pickle\n",
    "* Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used numpy's loadtxt and genfromtxt in October's sessions - these are fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Read in the data\n",
    "firstColFlt, secColFlt = np.loadtxt( \"random.txt\", dtype=float, usecols=[0,1], unpack=True )\n",
    "\n",
    "print( \"#-#-# firstColFlt\")\n",
    "print( firstColFlt )\n",
    "\n",
    "print( \"\\n#-#-# secColFlt\")\n",
    "print( secColFlt )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving in binary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy can save multiple arrays in a binary format with savez. If you read in data multiple times, it's likely worth it to write it to binary once, and then continue to read that. Watch the ordering as numpy doesn't save the array names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "np.savez('binaryNonCompressed.npz', firstColFlt, secColFlt)\n",
    "\n",
    "# Read it back in\n",
    "npzFile = np.load('binaryNonCompressed.npz')\n",
    "\n",
    "print( \"#-#-# files\")\n",
    "print( npzFile.files )\n",
    "\n",
    "print( \"\\n#-#-# arr_1\")\n",
    "print( npzFile['arr_1'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy also has a way to compress the binary data - this is slower (time for compression and decompresssion) but may be beneficial if you are moving data between clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "np.savez_compressed('binaryCompressed.npz', firstColFlt, secColFlt)\n",
    "\n",
    "# Read it back in\n",
    "npzCFile = np.load('binaryCompressed.npz')\n",
    "\n",
    "print( \"#-#-# files\")\n",
    "print( npzCFile.files )\n",
    "\n",
    "print( \"\\n#-#-# arr_0\")\n",
    "print( npzCFile['arr_0'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary reads and writes will always be faster than ascii.  Read your data in the original form one time and save it in a much better form for reading subsequent times. The python pickle package allows for very efficient I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "\n",
    "# Save to a pickle file\n",
    "pk.dump(firstColFlt, open( \"firstCol.pkl\", \"wb\"))\n",
    "\n",
    "# Read it back in\n",
    "readInFirstCol = pk.load( open( \"firstCol.pkl\", \"rb\"))\n",
    "\n",
    "print( \"#-#-# readInFirstCol\")\n",
    "print( readInFirstCol )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python2 has cPickle which is considerably faster for large data dumps and reads; Note that python3 uses cPickle by default - there is no change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cPickle if you are using python 2\n",
    "#import cPickle as pk\n",
    "\n",
    "# If you wish to manually force the c implementation of pickle, you can use _pickle\n",
    "import _pickle as pk\n",
    "\n",
    "# Save to a pickle file\n",
    "pk.dump(secColFlt, open( \"secCol.pkl\", \"wb\"))\n",
    "\n",
    "# Read it back in\n",
    "readInSecCol = pk.load( open( \"secCol.pkl\", \"rb\"))\n",
    "\n",
    "print( \"#-#-# readInSecCol\")\n",
    "print( readInSecCol )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have the same modes as with standard python files (w and r), but are also doing binary (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has read_csv, as well as some specialized I/O methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Names  Score  Unnamed: 2\n",
      "0  Billy     98         NaN\n",
      "1   Joel     95         NaN\n",
      "2  Elton     96         NaN\n",
      "3   John     85         NaN\n",
      "4  James     92         NaN\n",
      "5   Earl     91         NaN\n",
      "6  Jones     88         NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "testFrame = pd.read_csv( 'testScores.csv' )\n",
    "print( testFrame )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is an extra, unnamed column with NaNs because each line ends with a \",\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas binary using Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a built in method to store data using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Names  Score\n",
      "0  Billy     98\n",
      "1   Joel     95\n",
      "2  Elton     96\n",
      "3   John     85\n",
      "4  James     92\n",
      "5   Earl     91\n",
      "6  Jones     88\n"
     ]
    }
   ],
   "source": [
    "# Make a new frame without the right column\n",
    "noUnnamedFrame = testFrame.drop( columns = \"Unnamed: 2\" )\n",
    "\n",
    "# Save this to a pickle file\n",
    "noUnnamedFrame.to_pickle( 'testFrame.pkl' )\n",
    "\n",
    "# Read the file back in\n",
    "readFrame = pd.read_pickle( 'testFrame.pkl' )\n",
    "\n",
    "print( readFrame )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also has the ability to use hdf5, which can be coupled to many other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Names\n",
      "0  Billy\n",
      "1   Joel\n",
      "2  Elton\n",
      "3   John\n",
      "4  James\n",
      "5   Earl\n",
      "6  Jones\n"
     ]
    }
   ],
   "source": [
    "# Create a new frame without the score column\n",
    "namesFrame = noUnnamedFrame.drop( columns = \"Score\" )\n",
    "\n",
    "# Store this into an hdf5 file\n",
    "namesFrame.to_hdf('writingHDF5.h5','data')\n",
    "#hdf5File =  pd.HDFStore( 'storeFrame.h5' )\n",
    "#hdf5File['namesFrame'] = namesFrame\n",
    "#hdf5File.close()\n",
    "\n",
    "# Read this back in\n",
    "readInData = pd.read_hdf('writingHDF5.h5', mode='r')\n",
    "\n",
    "print( readInData )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to use in our examples\n",
    "import numpy as np\n",
    "alpha = np.arange(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write alpha to a compressed binary file using numpy.  Read this back in and save the variable as beta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save beta as a pickle file.  Read this back in and save the variable as omega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
